{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bosch Kaggle Script\n",
    "## To Do:\n",
    "* Objectify\n",
    "* LabelEncode Data?\n",
    "* Decision Tree\n",
    "* K-cross validation (going to be kind of tricky) Could just do within batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import subprocess\n",
    "import time\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "# Chunksize that seems to work for 32GB of RAM\n",
    "# Possible modify this\n",
    "# chunksize = 50000\n",
    "chunksize = 5000\n",
    "\n",
    "file_names = {}\n",
    "file_names['train'] = {}\n",
    "file_names['test'] = {}\n",
    "\n",
    "# file_names['train']['date'] = 'data/train_date.csv'\n",
    "file_names['train']['categorical'] = 'data/train_categorical.csv'\n",
    "file_names['train']['numeric'] = 'data/train_numeric.csv'\n",
    "# file_names['test']['date'] = 'data/test_date.csv'\n",
    "file_names['test']['categorical'] = 'data/test_categorical.csv'\n",
    "file_names['test']['numeric'] = 'data/test_numeric.csv'\n",
    "\n",
    "model_dir = 'data/models/'\n",
    "sub_dir = 'data/submissions/'\n",
    "\n",
    "# This is for the categories and date\n",
    "d = defaultdict(LabelEncoder)\n",
    "\n",
    "\n",
    "# XGBoost stuff\n",
    "num_rounds = 2\n",
    "params = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_save_models():\n",
    "    # This is what will be returned\n",
    "#     nlines = subprocess.check_output('wc -l %s' % file_names['train']['numeric'], shell=True)\n",
    "#     nlines = int(nlines.split()[0])\n",
    "    nlines = 100000\n",
    "    train_types = {}\n",
    "    train_columns = {}\n",
    "    \n",
    "    for file_name in file_names['train']:\n",
    "        train_data = pd.read_csv(file_names['train'][file_name], nrows=2)\n",
    "        train_types[file_name] = train_data.dtypes\n",
    "        train_columns[file_name] = train_data.columns\n",
    "    \n",
    "    time_start = time.time()\n",
    "    total_start = time_start\n",
    "    \n",
    "    total_sum = {}\n",
    "    \n",
    "    total_sum[0] = 0\n",
    "    total_sum[1] = 0\n",
    "    \n",
    "    for i in range(1, nlines, chunksize):\n",
    "        print('training on lines: %d - %d' % (i-1, i+chunksize-1))\n",
    "        train_data_parts = {}\n",
    "        for file_name in file_names['train']:\n",
    "            train_data_parts[file_name] = pd.read_csv(\n",
    "                file_names['train'][file_name],\n",
    "                index_col=0,\n",
    "                header=None,\n",
    "                names=train_columns[file_name],\n",
    "                nrows=chunksize,\n",
    "                skiprows=i,\n",
    "                dtype=train_types[file_name]\n",
    "                )\n",
    "        \n",
    "        # Let's normalize or whatever\n",
    "        train_data_df = train_data_parts['numeric'].join(train_data_parts['categorical']).apply(LabelEncoder().fit_transform)\n",
    "        \n",
    "        d_train = xgb.DMatrix(train_data_df.as_matrix(), label=train_data_df['Response'])\n",
    "        \n",
    "        # run this shit\n",
    "        bst = xgb.cv(params, d_train, num_rounds, nfold=5, metrics={'error'}, verbose_eval=True)\n",
    "        bst.save.save_model('data/models/test_model.' + str(i) + '.model')\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_and_make_submission():    \n",
    "    # all of the line numbers are the same (I hope or we have bigger issues)\n",
    "#     nlines = subprocess.check_output('wc -l %s' % file_names['test']['numeric'], shell=True)\n",
    "#     nlines = int(nlines.split()[0])\n",
    "    nlines = 1000\n",
    "    test_types = {}\n",
    "    test_columns = {}\n",
    "    \n",
    "    for file_name in file_names['test']:\n",
    "        test_data = pd.read_csv(file_names['test'][file_name], nrows=2)\n",
    "        test_types[file_name] = test_data.dtypes\n",
    "        test_columns[file_name] = test_data.columns\n",
    "    \n",
    "    for file_name in file_names['test']:\n",
    "        test_data_parts[file_name] = pd.read_csv(\n",
    "                file_names['test'][file_name],\n",
    "                index_col=0,\n",
    "                header=None,\n",
    "                names=train_columns[file_name],\n",
    "                nrows=chunksize,\n",
    "                skiprows=i,\n",
    "                dtype=test_types[file_name]\n",
    "                )\n",
    "        \n",
    "    time_start = time.time()\n",
    "    total_start = time_start\n",
    "      \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "#     data.to_csv('submission.csv', mode='a', header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on lines: 0 - 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/lib/arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0+0\ttest-error:0+0\n",
      "[1]\ttrain-error:0+0\ttest-error:0+0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0157db667680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_save_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# test_and_make_submission()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2a8d68971477>\u001b[0m in \u001b[0;36mtrain_and_save_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# run this shit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_stdv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/models/test_model.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "train_and_save_models()\n",
    "# test_and_make_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Data\n",
    "\n",
    "#### Data Exploration\n",
    "\n",
    "Overall values counts\n",
    "{0: 99432, 1: 568}\n",
    "\n",
    "#### Benchmarks\n",
    "\n",
    "Test size is 1m lines\n",
    "This will need to be divided by 3 to handle the 3 different tables\n",
    "\n",
    "Chunk Size | Time to read (seconds)\n",
    " --- | --- \n",
    "10k |271.936368942\n",
    "25k |179.683248997\n",
    "50k |163.830753088\n",
    "75k | 158.054757118\n",
    "100k |145.901106119\n",
    "150k |150.089717865\n",
    "250k |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst.best_iteration\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
